{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제 정의\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a binary classifier based on k random features for each digit against all the other digits at MNIST dataset.\n",
    "\n",
    "Let x = (x_1, x_2, ... , x_m) be a vector representing an image in the dataset.\n",
    "\n",
    "The prediction function f_d(x; w) is defined by the linear combination of input vector x and the model parameter w for each digit d :\n",
    "\n",
    "f_d(x; w) = w_0 * 1 + w_1 * g_1 + w_2 * g_2 + ... + w_k * g_k \n",
    "\n",
    "where w = (w_0, w_1, ... , w_k) and the basis function g_k is defined by the inner product of random vector r_k and input vector x. \n",
    "\n",
    "You may want to try to use g_k = max( inner production( r_k, x ), 0 ) to see if it improves the performance.\n",
    "\n",
    "The prediction function f_d(x; w) should have the following values:\n",
    "\n",
    "f_d(x; w) = +1 if label(x) = d\n",
    "f_d(x; w) = -1 if label(x) is not d\n",
    "\n",
    "The optimal model parameter w is obtained by minimizing the following objective function for each digit d :\n",
    "\\sum_i ( f_d(x^(i); w) - y^(i) )^2\n",
    "\n",
    "and the label of input x is given by:\n",
    "\n",
    "argmax_d f_d(x; w)\n",
    "\n",
    "1. Compute an optimal model parameter using the training dataset for each classifier f_d(x, w)\n",
    "2. Compute (1) true positive rate, (2) error rate using (1) training dataset and (2) testing dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모듈 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute an optimal model parameter using the training dataset for each classifier f_d(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28 * 28크기의 랜덤 벡터 1000개를 -100 이상 100이하의 값을 가지고 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_v = []\n",
    "for i in range(0,1000):\n",
    "    r_v.append(np.random.uniform(-100,100,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([-0.72254829,  3.19454759, -4.0624533 , ..., -3.54886959,\n",
      "       -4.44109884, -2.52343013]), 1: array([-0.18705929, -4.18443919,  1.64693456, ..., -1.3095842 ,\n",
      "        1.51053281, -1.75180674]), 2: array([-0.95525303, -1.30840896,  0.83358349, ...,  1.3453345 ,\n",
      "        0.22275157,  3.47499215]), 3: array([-1.07666679,  7.25449384, -0.68155142, ...,  1.27501709,\n",
      "       -1.18583415,  2.35142979]), 4: array([-0.52243036, -4.44557417,  2.69156528, ...,  1.21823688,\n",
      "        2.24918714, -2.37223084]), 5: array([-0.44605947,  3.35925257, -6.0436259 , ..., -1.46100522,\n",
      "       -2.05726897,  2.78326134]), 6: array([-0.88490181, -2.31886095,  0.32071445, ...,  1.04551108,\n",
      "        0.92000189, -1.14728974]), 7: array([-0.56690924,  0.72052754, -0.28483894, ...,  0.50464734,\n",
      "        0.47622473, -0.3148575 ]), 8: array([-1.79370427,  1.4029289 ,  0.09256054, ...,  2.07420214,\n",
      "       -1.17398195,  1.55996428]), 9: array([-0.84446744, -3.67446718,  5.48711125, ..., -1.14349003,\n",
      "        3.47948576, -2.06003261])}\n"
     ]
    }
   ],
   "source": [
    "file_data   = \"mnist_train.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "size_row    = 28    # height of the image\n",
    "size_col    = 28    # width of the image\n",
    "\n",
    "num_image   = len(data)\n",
    "count       = 0     # count for the number of images\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "    return(data_normalized)\n",
    "\n",
    "\n",
    "# list_label  = np.empty(num_image, dtype=int)\n",
    "list_label = []\n",
    "int_data = []\n",
    "int_data_y = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\n",
    "X = dict()\n",
    "for line in data:\n",
    "    im_vector2 = []\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    for i in range(0,1000):\n",
    "        im_vector2.append(np.dot(im_vector,r_v[i]))\n",
    "    im_vector = np.asfarray(im_vector2)\n",
    "    im_vector   = normalize(im_vector)\n",
    "    im_vector = np.insert(im_vector, 0, 1)\n",
    "    int_data.append(im_vector)\n",
    "    list_label.append(int(label))\n",
    "    for x in range(0,10):\n",
    "        if x == int(label):\n",
    "            int_data_y[x].append(1.0)\n",
    "        else:\n",
    "            int_data_y[x].append(-1.0);\n",
    "    count += 1\n",
    "\n",
    "xn = np.array(int_data,dtype=float)\n",
    "for i in range(0,10):\n",
    "    X[i] = np.dot(np.linalg.pinv(xn) , np.array(int_data_y[i],dtype=float))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute true positive rate, error rate using training dataset\n",
    "### - 예측한 label (argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "tp = 0\n",
    "error = 0\n",
    "for x in range(len(xn)):\n",
    "    f1 = plt.figure(1)\n",
    "    argmax = []\n",
    "    for i in range(0,10):\n",
    "        argmax.append(np.dot(xn[x],X[i]))\n",
    "    label       = argmax.index(max(argmax))\n",
    "    if list_label[x] == label:\n",
    "        tp = tp + 1\n",
    "    else:\n",
    "        error = error + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive rate :0.8632666666666666\n",
      "error rate : 0.13673333333333335\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive rate :\" + str(tp/num_image))\n",
    "print(\"error rate : \" + str(error/num_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28 * 28크기의 랜덤 벡터 1000개를 0 이상 100이하의 값을 가지고 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_v = []\n",
    "for i in range(0,1000):\n",
    "    r_v.append(np.random.uniform(0,100,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([-0.4668312 , -1.69602874, -1.98363809, ...,  2.07035167,\n",
      "        3.01145283,  5.99737307]), 1: array([-0.14704801, -3.39493141, -5.98400725, ..., -3.47042636,\n",
      "       -1.20146487,  1.52225734]), 2: array([-0.45729751,  2.45246917, -3.39744655, ..., -0.02372528,\n",
      "       -0.64321627, -2.65970507]), 3: array([-0.94767904,  3.00556664, 10.52287724, ...,  1.05004842,\n",
      "       -3.45554081, -3.96145203]), 4: array([-0.31525493,  1.64914394, -4.85749609, ..., -1.81795399,\n",
      "       -0.61375117,  0.68506044]), 5: array([-0.63391791,  4.70887066, -2.17934349, ..., -0.95957429,\n",
      "       -1.15669778, -0.53074787]), 6: array([-1.25512835,  1.51018007,  5.05874818, ...,  1.23629766,\n",
      "        0.16299412,  1.19577497]), 7: array([-0.63156056, -0.3553204 ,  5.71788694, ..., -0.96553524,\n",
      "        2.51483294, -0.02089986]), 8: array([-2.23806658,  1.19901055,  3.36951911, ...,  1.83342694,\n",
      "        1.01419043, -3.15203179]), 9: array([-0.90721593, -9.07896046, -6.26709999, ...,  1.04709047,\n",
      "        0.36720058,  0.92437079])}\n"
     ]
    }
   ],
   "source": [
    "file_data   = \"mnist_train.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "size_row    = 28    # height of the image\n",
    "size_col    = 28    # width of the image\n",
    "\n",
    "num_image   = len(data)\n",
    "count       = 0     # count for the number of images\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "    return(data_normalized)\n",
    "\n",
    "\n",
    "# list_label  = np.empty(num_image, dtype=int)\n",
    "list_label = []\n",
    "int_data = []\n",
    "int_data_y = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\n",
    "X = dict()\n",
    "for line in data:\n",
    "    im_vector2 = []\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    for i in range(0,1000):\n",
    "        im_vector2.append(np.dot(im_vector,r_v[i]))\n",
    "    im_vector = np.asfarray(im_vector2)\n",
    "    im_vector   = normalize(im_vector)\n",
    "    im_vector = np.insert(im_vector, 0, 1)\n",
    "    int_data.append(im_vector)\n",
    "    list_label.append(int(label))\n",
    "    for x in range(0,10):\n",
    "        if x == int(label):\n",
    "            int_data_y[x].append(1.0)\n",
    "        else:\n",
    "            int_data_y[x].append(-1.0);\n",
    "    count += 1\n",
    "\n",
    "xn = np.array(int_data,dtype=float)\n",
    "for i in range(0,10):\n",
    "    X[i] = np.dot(np.linalg.pinv(xn) , np.array(int_data_y[i],dtype=float))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "tp = 0\n",
    "error = 0\n",
    "for x in range(len(xn)):\n",
    "    f1 = plt.figure(1)\n",
    "    argmax = []\n",
    "    for i in range(0,10):\n",
    "        argmax.append(np.dot(xn[x],X[i]))\n",
    "    label       = argmax.index(max(argmax))\n",
    "    if list_label[x] == label:\n",
    "        tp = tp + 1\n",
    "    else:\n",
    "        error = error + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive rate :0.86505\n",
      "error rate : 0.13495\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive rate :\" + str(tp/num_image))\n",
    "print(\"error rate : \" + str(error/num_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute true positive rate, error rate using testing dataset\n",
    "### - 예측한 label (argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data   = \"mnist_test.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "size_row    = 28    # height of the image\n",
    "size_col    = 28    # width of the image\n",
    "\n",
    "num_image   = len(data)\n",
    "count       = 0     # count for the number of images\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "    return(data_normalized)\n",
    "\n",
    "\n",
    "# list_label  = np.empty(num_image, dtype=int)\n",
    "list_label = []\n",
    "int_data = []\n",
    "for line in data:\n",
    "    im_vector2 = []\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    for i in range(0,1000):\n",
    "        im_vector2.append(np.inner(im_vector,r_v[i]))\n",
    "    im_vector = np.asfarray(im_vector2)\n",
    "    im_vector   = normalize(im_vector)\n",
    "    im_vector = np.insert(im_vector, 0, 1)\n",
    "    int_data.append(im_vector)\n",
    "    list_label.append(int(label))\n",
    "\n",
    "xn = np.array(int_data,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "tp = 0\n",
    "error = 0\n",
    "for x in range(len(xn)):\n",
    "    f1 = plt.figure(1)\n",
    "    argmax = []\n",
    "    for i in range(0,10):\n",
    "        argmax.append(np.dot(xn[x],X[i]))\n",
    "    label       = argmax.index(max(argmax))\n",
    "    if list_label[x] == label:\n",
    "        tp = tp + 1\n",
    "    else:\n",
    "        error = error + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive rate :0.8658\n",
      "error rate : 0.1342\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive rate :\" + str(tp/num_image))\n",
    "print(\"error rate : \" + str(error/num_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# g_k = max( inner production( r_k, x ), 0 ) 의 성능향상도 확인할 수 있었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
